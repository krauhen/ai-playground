{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f786522-9dd9-4828-ab8d-ef65d4fc3ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "import torch\n",
    "import sys\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import gradio as gr\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46b9d63-2dae-4f34-b07d-518160117aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_PATH = \"../data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef55422e-f520-454a-8f6f-fb30a8505861",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(filenames):\n",
    "    n = 2\n",
    "    m = 2\n",
    "    fig, axes = plt.subplots(n, m, figsize=(20, 5))\n",
    "    for i in range(n):\n",
    "        for j in range(m):\n",
    "            idx = (i * m) + j\n",
    "            img = cv2.imread(filenames[idx])\n",
    "            img[:, :, [0, 1, 2]] = img[:, :, [2, 1, 0]]\n",
    "            axes[i, j].imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb93a90e-e486-4fe8-b0c2-2d8cdd2e9fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = sorted(glob.glob(os.path.join(FILE_PATH, \"images\\*\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaba2fdf-278b-4f02-8b00-f2faf62e4af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6590a68c-3bd7-433c-9d97-49bc0973eddc",
   "metadata": {},
   "source": [
    "# Save image in correct rotation to ease things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fee25d-cc14-4387-8d38-892248b8dc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename in filenames:\n",
    "    img = cv2.imread(filename)\n",
    "    h, w, c = img.shape\n",
    "    if w > h:\n",
    "        if sys.platform.startswith('linux'):\n",
    "            print(\"save\", \"linux\", filename)\n",
    "            img = img.transpose(0, 2, 1)\n",
    "        else:\n",
    "            print(\"save\", \"windows\", filename)\n",
    "            img = cv2.rotate(img, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "        cv2.imwrite(filename, img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de838239-3dba-4775-b5db-4dd2f25a141a",
   "metadata": {},
   "source": [
    "# Model definition for pre prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e4070f-74ae-48c2-a757-1fcdd4f8a506",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = nn.Sequential(nn.Conv2d(3, 32, kernel_size=4, stride=2, padding=1),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=1),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.AvgPool2d(2, 2),\n",
    "                                     nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.AvgPool2d(2, 2),\n",
    "                                     nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1),\n",
    "                                     nn.ReLU(),\n",
    "                                     nn.Conv2d(512, 1024, kernel_size=4, stride=2, padding=1),\n",
    "                                     nn.ReLU())\n",
    "\n",
    "        self.dropout = nn.Dropout(p=0.25)\n",
    "\n",
    "        self.out = nn.Sequential(nn.Linear(1024, 128),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Linear(128, 128),\n",
    "                                 nn.ReLU(),\n",
    "                                 nn.Linear(128, 3 + 3))\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.encoder(x)\n",
    "        latent = x.view(x.shape[0], -1)\n",
    "        latent = self.dropout(latent)\n",
    "        x = self.out(latent)\n",
    "        visible = F.softmax(x[:, :3], dim=-1)\n",
    "        text = F.softmax(x[:, 3:], dim=-1)\n",
    "        \n",
    "        return visible, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105f634a-0980-4f4f-a4db-03b81b90df82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_to_json_file(payload):\n",
    "\n",
    "    filename = os.path.join(FILE_PATH, \"data.json\")\n",
    "\n",
    "    if not os.path.isfile(filename):\n",
    "        print(f\"Creat file {filename}\")\n",
    "        with open(filename, \"w\") as f:\n",
    "            json.dump({\"entries\": []}, f)\n",
    "    \n",
    "    with open(filename, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    data[\"entries\"].append(payload)\n",
    "    print(data)\n",
    "    \n",
    "    with open(filename, \"w\") as f:\n",
    "        json.dump(data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64e1de1-da9d-405b-bdd3-81c1dae9cb8c",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766ba96e-9b5a-45b3-9960-3b3dfe4dedb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HEIGHT = 4032\n",
    "# WIDTH = 3024\n",
    "# DEVICE = \"cuda\"\n",
    "# checkpoint = torch.load(f\"/mnt/data/checkpoints/bill_detection.pth\")\n",
    "# model = Model().to(DEVICE)\n",
    "# _ = model.load_state_dict(checkpoint[\"model_state_dict\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c13fbd-de29-4a8a-a8fa-4d4e0c0f98e9",
   "metadata": {},
   "source": [
    "# Gradio application running in a separat browser tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8b4a69-08f1-466b-a29e-73857c0b33a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_app():\n",
    "    def get_image_patch(filename, patch_size=(256, 256)):\n",
    "\n",
    "        img = cv2.imread(filename)\n",
    "        h, w, c = img.shape\n",
    "\n",
    "        img[:, :, [0, 1, 2]] = img[:, :, [2, 1, 0]]\n",
    "        \n",
    "        ph, pw = patch_size\n",
    "        ry = np.random.randint(0, h - ph)\n",
    "        rx = np.random.randint(0, w - pw)\n",
    "        patch = img[ry:ry + ph, rx:rx + pw]\n",
    "        upper_left = rx, ry\n",
    "        lower_right = rx + pw, ry + ph\n",
    "\n",
    "        coord = upper_left, lower_right\n",
    "\n",
    "        img = cv2.rectangle(img.copy(), (rx, ry), (rx + pw, ry + ph), (255, 0, 0), 10)\n",
    "        img = cv2.resize(img, None, fx=0.25, fy=0.25)\n",
    "        h, w, c = img.shape\n",
    "\n",
    "        #####################################################################################\n",
    "        #####################################################################################\n",
    "        #####################################################################################\n",
    "\n",
    "        # visible_categories = [\"yes\", \"no\", \"unclear\"]\n",
    "        # text_categories = [\"yes\", \"no\", \"unclear\"]\n",
    "        \n",
    "        # patch_tensor = patch.copy()\n",
    "        # patch_tensor = torch.from_numpy(patch_tensor) / 255\n",
    "        # patch_tensor = patch_tensor.permute(2, 0, 1)\n",
    "        # patch_tensor = patch_tensor[None, :]\n",
    "        # patch_tensor = patch_tensor.to(DEVICE)\n",
    "\n",
    "        # visible, text = model(patch_tensor)\n",
    "        # visible_idx = visible.detach().cpu().numpy().argmax(axis=1)[0]\n",
    "        # text_idx = text.detach().cpu().numpy().argmax(axis=1)[0]\n",
    "\n",
    "        # pred_label_visible = visible_categories[visible_idx]\n",
    "        # pred_label_text = text_categories[text_idx]\n",
    "        \n",
    "        #####################################################################################\n",
    "        #####################################################################################\n",
    "        #####################################################################################\n",
    "\n",
    "        pred_label_visible = None\n",
    "        pred_label_text = None\n",
    "        \n",
    "        return img, patch, coord, pred_label_visible, pred_label_text, h, w\n",
    "        \n",
    "    with gr.Blocks(theme=\"adam-haile/DSTheme\") as demo:\n",
    "    \n",
    "        idx = np.random.randint(0, len(filenames))\n",
    "        filename = filenames[idx]\n",
    "        img, patch, coord, pred_label_visible, pred_label_text, h, w = get_image_patch(filename)\n",
    "\n",
    "        with gr.Row():\n",
    "            big_image = gr.Image(img, height=h, width=w, label=\"Full image for reference\")\n",
    "            image = gr.Image(patch, height=h, width=w, label=\"Patch to label\")\n",
    "        \n",
    "        label_visible_radio = gr.Radio(value=pred_label_visible, \n",
    "                                       choices=[\"yes\", \"no\", \"unclear\"], \n",
    "                                       label=\"Is the bill visible in the image?\")\n",
    "        \n",
    "        label_text_radio = gr.Radio(value=pred_label_text, \n",
    "                                    choices=[\"yes\", \"no\", \"unclear\"], \n",
    "                                    label=\"Is text visible in the image?\")\n",
    "        \n",
    "        filename_text = gr.Text(filename, \n",
    "                                label=\"filename\", \n",
    "                                interactive=False)\n",
    "        \n",
    "        coord_text = gr.Text(coord, \n",
    "                             label=\"coord\", \n",
    "                             interactive=False)\n",
    "        \n",
    "        output_textbox = gr.Textbox(label=\"Submitted data\", \n",
    "                                    interactive=False)\n",
    "            \n",
    "        button = gr.Button(\"Submit\")\n",
    "    \n",
    "        @button.click(inputs=[label_visible_radio, \n",
    "                              label_text_radio, \n",
    "                              filename_text, \n",
    "                              coord_text], \n",
    "                      outputs=[output_textbox, \n",
    "                               label_visible_radio, \n",
    "                               label_text_radio, \n",
    "                               filename_text,\n",
    "                               coord_text,\n",
    "                               big_image,\n",
    "                               image])\n",
    "        def submit(label_visible, label_text, filename, coord):\n",
    "            \n",
    "            idx = np.random.randint(0, len(filenames))\n",
    "            new_filename = filenames[idx]\n",
    "            img, patch, new_coord, pred_label_visible, pred_label_text, h, w = get_image_patch(filename)\n",
    "    \n",
    "            entry = dict()\n",
    "            entry[\"label_visible\"] = label_visible\n",
    "            entry[\"label_text\"] = label_text\n",
    "            entry[\"filename\"] = filename\n",
    "            entry[\"coord\"] = coord\n",
    "            \n",
    "            append_to_json_file(entry)\n",
    "            text = f\"{label_visible=}, {label_text=}, {filename=}, {coord=}\"\n",
    "    \n",
    "            return text, pred_label_visible, pred_label_text, new_filename, new_coord, img, patch\n",
    "    \n",
    "    _ = demo.launch(inline=False, inbrowser=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af23bee0-82ff-4eaa-b44d-576f9609dafb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "create_app()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8919dc62-d7fa-4330-b877-160b24f665b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
