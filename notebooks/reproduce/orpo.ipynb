{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50798a82-ef70-4e42-86e9-ddc62108f1ee",
   "metadata": {},
   "source": [
    "# Source\n",
    "# https://huggingface.co/blog/mlabonne/orpo-llama-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98b020c7-e1ea-4d8a-9b63-f65b3af7ab52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/henning/.local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import os\n",
    "\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, PeftModel, prepare_model_for_kbit_training\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    "    pipeline,\n",
    ")\n",
    "from trl import ORPOConfig, ORPOTrainer, setup_chat_format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21797f14-0d23-476e-91e7-57df9b0f06a8",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bc3f334-1ddb-4330-8c10-0ad956f0096f",
   "metadata": {},
   "outputs": [],
   "source": [
    "access_token = \"hf_XXX\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "089e047b-6f00-44bd-9465-6f21ce72aa7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flash attention\n",
    "attn_implementation = \"flash_attention_2\"\n",
    "torch_dtype = torch.bfloat16\n",
    "\n",
    "N_EPOCHS = 1\n",
    "\n",
    "# Model\n",
    "base_model = \"meta-llama/Meta-Llama-3-8B\"\n",
    "new_model = \"Custom-OrpoLlama-3-8B\"\n",
    "\n",
    "# QLoRA config\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch_dtype,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "# LoRA config\n",
    "peft_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    target_modules=['up_proj', 'down_proj', 'gate_proj', 'k_proj', 'q_proj', 'v_proj', 'o_proj']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39403438-adf6-46a8-b7a8-a1b04f3726ed",
   "metadata": {},
   "source": [
    "# Model and Tokenizer setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "230a175e-90b4-4225-8d96-2e7577172953",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:06<00:00,  1.57s/it]\n"
     ]
    }
   ],
   "source": [
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    base_model,\n",
    "    token=access_token)\n",
    "\n",
    "# Load model\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    attn_implementation=attn_implementation,\n",
    "    token=access_token\n",
    ")\n",
    "\n",
    "model, tokenizer = setup_chat_format(model, tokenizer)\n",
    "\n",
    "model = prepare_model_for_kbit_training(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dec70b8-5407-448b-aaa7-211da92804a8",
   "metadata": {},
   "source": [
    "# Dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a5130a7-406d-480a-b611-21445a06cbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"mlabonne/orpo-dpo-mix-40k\"\n",
    "dataset = load_dataset(dataset_name, split=\"all\")\n",
    "dataset = dataset.shuffle(seed=42)\n",
    "dataset = dataset.select(range(1000))\n",
    "\n",
    "def format_chat_template(row):\n",
    "    row[\"chosen\"] = tokenizer.apply_chat_template(row[\"chosen\"], tokenize=False)\n",
    "    row[\"rejected\"] = tokenizer.apply_chat_template(row[\"rejected\"], tokenize=False)\n",
    "    return row\n",
    "\n",
    "# Process entries when called to fit the correct template\n",
    "dataset = dataset.map(\n",
    "    format_chat_template,\n",
    "    num_proc= os.cpu_count(),\n",
    ")\n",
    "dataset = dataset.train_test_split(test_size=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b673197-44db-4a07-9d33-dc97f5537f59",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c31d5c7-1019-4fcb-aede-aa8ace169d93",
   "metadata": {},
   "source": [
    "## Configure Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15fbe89e-a54c-4791-ab9e-8d86a2e1bee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 999/999 [00:02<00:00, 419.78 examples/s]\n",
      "Map: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 203.72 examples/s]\n"
     ]
    }
   ],
   "source": [
    "orpo_args = ORPOConfig(\n",
    "    learning_rate=8e-6,\n",
    "    beta=0.1,\n",
    "    lr_scheduler_type=\"linear\",\n",
    "    max_length=1024,\n",
    "    max_prompt_length=512,\n",
    "    per_device_train_batch_size=2,\n",
    "    per_device_eval_batch_size=2,\n",
    "    gradient_accumulation_steps=4,\n",
    "    optim=\"paged_adamw_8bit\",\n",
    "    num_train_epochs=N_EPOCHS,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=10,\n",
    "    logging_steps=10,\n",
    "    warmup_steps=10,\n",
    "    output_dir=\"./results/\",\n",
    "    remove_unused_columns=False,\n",
    ")\n",
    "\n",
    "trainer = ORPOTrainer(\n",
    "    model=model,\n",
    "    args=orpo_args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    eval_dataset=dataset[\"test\"],\n",
    "    peft_config=peft_config,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8ccc73-ccac-4e1f-9654-2af82ae2636a",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd4ea00c-b425-42d0-bf2e-82ee636105b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/henning/.local/lib/python3.11/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n",
      "The input hidden states seems to be silently casted in float32, this might be related to the fact you have upcasted embedding or layer norm layers in float32. We will cast back the input in torch.float16.\n",
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [125/125 57:49, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Samples Per Second</th>\n",
       "      <th>Steps Per Second</th>\n",
       "      <th>Rewards/chosen</th>\n",
       "      <th>Rewards/rejected</th>\n",
       "      <th>Rewards/accuracies</th>\n",
       "      <th>Rewards/margins</th>\n",
       "      <th>Logps/rejected</th>\n",
       "      <th>Logps/chosen</th>\n",
       "      <th>Logits/rejected</th>\n",
       "      <th>Logits/chosen</th>\n",
       "      <th>Nll Loss</th>\n",
       "      <th>Log Odds Ratio</th>\n",
       "      <th>Log Odds Chosen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>3.363100</td>\n",
       "      <td>1.389156</td>\n",
       "      <td>0.847400</td>\n",
       "      <td>1.180000</td>\n",
       "      <td>1.180000</td>\n",
       "      <td>-0.118680</td>\n",
       "      <td>-0.133936</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.015255</td>\n",
       "      <td>-1.339357</td>\n",
       "      <td>-1.186802</td>\n",
       "      <td>-1.159615</td>\n",
       "      <td>-0.996206</td>\n",
       "      <td>1.329918</td>\n",
       "      <td>-0.592375</td>\n",
       "      <td>0.212849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.632800</td>\n",
       "      <td>1.361720</td>\n",
       "      <td>0.777100</td>\n",
       "      <td>1.287000</td>\n",
       "      <td>1.287000</td>\n",
       "      <td>-0.116060</td>\n",
       "      <td>-0.130229</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.014169</td>\n",
       "      <td>-1.302286</td>\n",
       "      <td>-1.160596</td>\n",
       "      <td>-1.217011</td>\n",
       "      <td>-1.018003</td>\n",
       "      <td>1.301916</td>\n",
       "      <td>-0.598041</td>\n",
       "      <td>0.200217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.441300</td>\n",
       "      <td>1.330022</td>\n",
       "      <td>0.763400</td>\n",
       "      <td>1.310000</td>\n",
       "      <td>1.310000</td>\n",
       "      <td>-0.113001</td>\n",
       "      <td>-0.126362</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013361</td>\n",
       "      <td>-1.263620</td>\n",
       "      <td>-1.130010</td>\n",
       "      <td>-1.245288</td>\n",
       "      <td>-1.041515</td>\n",
       "      <td>1.269828</td>\n",
       "      <td>-0.601940</td>\n",
       "      <td>0.191575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.133900</td>\n",
       "      <td>1.279973</td>\n",
       "      <td>0.815300</td>\n",
       "      <td>1.226000</td>\n",
       "      <td>1.226000</td>\n",
       "      <td>-0.108497</td>\n",
       "      <td>-0.121349</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.012852</td>\n",
       "      <td>-1.213489</td>\n",
       "      <td>-1.084972</td>\n",
       "      <td>-1.268364</td>\n",
       "      <td>-1.072785</td>\n",
       "      <td>1.219628</td>\n",
       "      <td>-0.603446</td>\n",
       "      <td>0.188249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.219700</td>\n",
       "      <td>1.205585</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>1.220000</td>\n",
       "      <td>1.220000</td>\n",
       "      <td>-0.103205</td>\n",
       "      <td>-0.116395</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013191</td>\n",
       "      <td>-1.163955</td>\n",
       "      <td>-1.032045</td>\n",
       "      <td>-1.270852</td>\n",
       "      <td>-1.074382</td>\n",
       "      <td>1.145684</td>\n",
       "      <td>-0.599009</td>\n",
       "      <td>0.198069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.063000</td>\n",
       "      <td>1.156024</td>\n",
       "      <td>0.794500</td>\n",
       "      <td>1.259000</td>\n",
       "      <td>1.259000</td>\n",
       "      <td>-0.098424</td>\n",
       "      <td>-0.112520</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.014097</td>\n",
       "      <td>-1.125205</td>\n",
       "      <td>-0.984238</td>\n",
       "      <td>-1.253186</td>\n",
       "      <td>-1.053992</td>\n",
       "      <td>1.096949</td>\n",
       "      <td>-0.590745</td>\n",
       "      <td>0.216500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.065900</td>\n",
       "      <td>1.113467</td>\n",
       "      <td>0.909900</td>\n",
       "      <td>1.099000</td>\n",
       "      <td>1.099000</td>\n",
       "      <td>-0.094146</td>\n",
       "      <td>-0.108651</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.014505</td>\n",
       "      <td>-1.086506</td>\n",
       "      <td>-0.941457</td>\n",
       "      <td>-1.249596</td>\n",
       "      <td>-1.039540</td>\n",
       "      <td>1.054898</td>\n",
       "      <td>-0.585689</td>\n",
       "      <td>0.227868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.063500</td>\n",
       "      <td>1.089055</td>\n",
       "      <td>0.770800</td>\n",
       "      <td>1.297000</td>\n",
       "      <td>1.297000</td>\n",
       "      <td>-0.091766</td>\n",
       "      <td>-0.105960</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.014193</td>\n",
       "      <td>-1.059599</td>\n",
       "      <td>-0.917665</td>\n",
       "      <td>-1.243919</td>\n",
       "      <td>-1.027465</td>\n",
       "      <td>1.030416</td>\n",
       "      <td>-0.586390</td>\n",
       "      <td>0.226288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.073100</td>\n",
       "      <td>1.074691</td>\n",
       "      <td>0.826900</td>\n",
       "      <td>1.209000</td>\n",
       "      <td>1.209000</td>\n",
       "      <td>-0.090680</td>\n",
       "      <td>-0.104449</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013769</td>\n",
       "      <td>-1.044486</td>\n",
       "      <td>-0.906799</td>\n",
       "      <td>-1.241005</td>\n",
       "      <td>-1.026939</td>\n",
       "      <td>1.015827</td>\n",
       "      <td>-0.588641</td>\n",
       "      <td>0.221223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.004800</td>\n",
       "      <td>1.056785</td>\n",
       "      <td>0.782500</td>\n",
       "      <td>1.278000</td>\n",
       "      <td>1.278000</td>\n",
       "      <td>-0.089487</td>\n",
       "      <td>-0.103486</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.013999</td>\n",
       "      <td>-1.034861</td>\n",
       "      <td>-0.894873</td>\n",
       "      <td>-1.241864</td>\n",
       "      <td>-1.032764</td>\n",
       "      <td>0.998151</td>\n",
       "      <td>-0.586332</td>\n",
       "      <td>0.226419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>1.006400</td>\n",
       "      <td>1.042757</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>1.290000</td>\n",
       "      <td>1.290000</td>\n",
       "      <td>-0.088325</td>\n",
       "      <td>-0.102918</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.014593</td>\n",
       "      <td>-1.029175</td>\n",
       "      <td>-0.883245</td>\n",
       "      <td>-1.244671</td>\n",
       "      <td>-1.035610</td>\n",
       "      <td>0.984606</td>\n",
       "      <td>-0.581507</td>\n",
       "      <td>0.237329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.982400</td>\n",
       "      <td>1.037311</td>\n",
       "      <td>0.838200</td>\n",
       "      <td>1.193000</td>\n",
       "      <td>1.193000</td>\n",
       "      <td>-0.087822</td>\n",
       "      <td>-0.102666</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.014844</td>\n",
       "      <td>-1.026664</td>\n",
       "      <td>-0.878221</td>\n",
       "      <td>-1.245571</td>\n",
       "      <td>-1.034473</td>\n",
       "      <td>0.979366</td>\n",
       "      <td>-0.579450</td>\n",
       "      <td>0.241999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/henning/.local/lib/python3.11/site-packages/peft/utils/other.py:581: UserWarning: Unable to fetch remote file due to the following error 401 Client Error. (Request ID: Root=1-6638db91-05434e750a45b3b67dfe7aa5;f60553f3-fd54-4630-aa82-b8ace4f7ac89)\n",
      "\n",
      "Cannot access gated repo for url https://huggingface.co/meta-llama/Meta-Llama-3-8B/resolve/main/config.json.\n",
      "Access to model meta-llama/Meta-Llama-3-8B is restricted. You must be authenticated to access it. - silently ignoring the lookup for the file config.json in meta-llama/Meta-Llama-3-8B.\n",
      "  warnings.warn(\n",
      "/home/henning/.local/lib/python3.11/site-packages/peft/utils/save_and_load.py:154: UserWarning: Could not find a config file in meta-llama/Meta-Llama-3-8B - will assume that the vocabulary was not modified.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "trainer.save_model(new_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3cd766-26d0-4f78-83e6-9299a15f3380",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a72929c2-1bae-46c1-8571-02ca5a40e09e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Loading checkpoint shards: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:06<00:00,  1.51s/it]\n"
     ]
    }
   ],
   "source": [
    "# Flush memory\n",
    "del trainer, model\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Reload tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model,\n",
    "    low_cpu_mem_usage=True,\n",
    "    return_dict=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "model, tokenizer = setup_chat_format(model, tokenizer)\n",
    "\n",
    "# Merge adapter with base model\n",
    "model = PeftModel.from_pretrained(model, new_model)\n",
    "model = model.merge_and_unload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a71cb6-3026-408b-8c33-452308193295",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_ = model.push_to_hub(new_model, use_temp_dir=False, token=access_token)\n",
    "_ = tokenizer.push_to_hub(new_model, use_temp_dir=False, token=access_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa84ac8-8f1c-4c0d-a7df-fd85b068598c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
