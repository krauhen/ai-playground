{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad879c98-a14d-4089-8b4e-d5041c532a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/henning/.local/lib/python3.11/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import glob\n",
    "import math\n",
    "import os\n",
    "import torch\n",
    "import pathlib\n",
    "import time\n",
    "import tiktoken\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.utils.data as torch_data\n",
    "import torchvision as tv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dea7c5e8-638b-47b9-aff1-835209c2ab25",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch_data.Dataset):\n",
    "    def __init__(self, tokenizer, len_context):\n",
    "\n",
    "        self.tokenizer = tiktoken.encoding_for_model(tokenizer)\n",
    "        self.len_context = len_context\n",
    "        self.elements = sorted(glob.glob(f\"/mnt/data/wikipedia/tokens/{tokenizer}/{len_context}/*\")) \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.elements)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        tokens_filename = self.elements[idx]\n",
    "        filename = tokens_filename.split(\"/\")[-1]\n",
    "        text_filename = os.path.join(f\"/mnt/data/wikipedia/text\", filename)\n",
    "        \n",
    "        with open(tokens_filename, \"rb\") as f:\n",
    "            tokens = json.load(f)[\"tokens\"]\n",
    "\n",
    "        with open(text_filename, \"rb\") as f:\n",
    "            text = json.load(f)[\"text\"]\n",
    "\n",
    "        tokens = tokens[:self.len_context + 1]\n",
    "        tokens = torch.from_numpy(np.array(tokens)).to(torch.long)\n",
    "        \n",
    "        element = dict()\n",
    "        element[\"text\"] = text\n",
    "        element[\"tokens\"] = tokens\n",
    "\n",
    "        return element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "142db1df-fb59-44ae-a256-2cc705624e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "SHUFFLE = True\n",
    "NUM_WORKERS = 16\n",
    "DEVICE = \"cuda\"\n",
    "LR = 1e-4\n",
    "N_EPOCHS = 100\n",
    "BATCH_SIZE = 32 + 8\n",
    "BATCH_SUM = 32\n",
    "\n",
    "TOKENIZER = \"gpt2\"\n",
    "LEN_CONTEXT = 256\n",
    "N_EMB = 2048\n",
    "N_HEADS = 12\n",
    "N_LAYERS = 7\n",
    "DROPOUT = 0.1\n",
    "\n",
    "FILE_PATH = \"models/text_embedding.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c061d751-30c2-49dc-a1fd-b0cccc0bf76a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3735788\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset(TOKENIZER, LEN_CONTEXT)\n",
    "VOCAB_SIZE = dataset.tokenizer.n_vocab\n",
    "loader = torch_data.DataLoader(dataset, shuffle=SHUFFLE, pin_memory=True, num_workers=NUM_WORKERS, batch_size=BATCH_SIZE)\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e855991-974c-44f2-af55-a7d59c2c987a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([257])\n",
      "torch.Size([40, 257])\n"
     ]
    }
   ],
   "source": [
    "element = dataset[np.random.randint(0, len(dataset))]\n",
    "tokens = element[\"tokens\"]\n",
    "print(tokens.shape)\n",
    "batch = next(iter(loader))\n",
    "tokens = batch[\"tokens\"]\n",
    "print(tokens.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7a94013-d437-4755-bbe7-2f3090bc8407",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    def __init__(self, head_size, n_embd, block_size, dropout):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B,T,C = x.shape\n",
    "        k = self.key(x)\n",
    "        q = self.query(x)\n",
    "        wei = q @ k.transpose(-2,-1) * k.shape[-1]**-0.5\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf'))\n",
    "        wei = F.softmax(wei, dim=-1)\n",
    "        wei = self.dropout(wei)\n",
    "        v = self.value(x)\n",
    "        out = wei @ v\n",
    "        return out\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, num_heads, head_size, n_embd, block_size, dropout):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size, n_embd, block_size, dropout) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(head_size * num_heads, n_embd)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out\n",
    "class FeedFoward(nn.Module):\n",
    "    def __init__(self, n_embd, dropout):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4 * n_embd),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embd, n_embd),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, n_head, n_embd, block_size, dropout):\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head\n",
    "        self.sa = MultiHeadAttention(n_head, head_size, n_embd, block_size, dropout)\n",
    "        self.ffwd = FeedFoward(n_embd, dropout)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.sa(self.ln1(x))\n",
    "        x = x + self.ffwd(self.ln2(x))\n",
    "        return x\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, vocab_size, n_embd, block_size, n_head, n_layer, dropout):\n",
    "        super().__init__()\n",
    "        self.block_size = block_size\n",
    "        self.token_embedding = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding = nn.Embedding(block_size, n_embd)\n",
    "\n",
    "        shape = 0\n",
    "        blocks = []\n",
    "        for i in range(n_layer):\n",
    "            blocks.append(Block(n_head, n_embd // 2**i, block_size, dropout))\n",
    "            blocks.append(nn.AvgPool1d(kernel_size=2, stride=2))\n",
    "            shape = n_embd // 2**(i + 1)\n",
    "        self.down_blocks = nn.Sequential(*blocks)\n",
    "        \n",
    "        blocks = []\n",
    "        for i in range(n_layer):\n",
    "            blocks.append(Block(n_head, shape, block_size, dropout))\n",
    "            blocks.append(nn.Upsample(scale_factor=2, mode='nearest'))\n",
    "            shape = shape * 2\n",
    "        self.up_blocks = nn.Sequential(*blocks)\n",
    "        \n",
    "        self.ln_f = nn.LayerNorm(n_embd)\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    def forward(self, idx):\n",
    "        tok_emb = self.token_embedding(idx)\n",
    "        pos_emb = self.position_embedding(torch.arange(idx.shape[1], device=idx.device))\n",
    "        x = tok_emb + pos_emb \n",
    "        latent = self.down_blocks(x)\n",
    "        x = self.up_blocks(latent)\n",
    "        x = self.ln_f(x)\n",
    "        logits = self.lm_head(x)\n",
    "        return logits, latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9780dfb-e78c-4b29-87be-44a11ca23253",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(epoch, batch, batch_acc, token_count, losses, ppls, model, optimizer, scaler, path):\n",
    "    checkpoint = dict()\n",
    "    checkpoint[\"epoch\"] = epoch\n",
    "    checkpoint[\"batch\"] = batch\n",
    "    checkpoint[\"batch_acc\"] = batch_acc\n",
    "    checkpoint[\"token_count\"] = token_count\n",
    "    checkpoint[\"model_state_dict\"] = model.state_dict()\n",
    "    checkpoint[\"optimizer_state_dict\"] = optimizer.state_dict()\n",
    "    checkpoint[\"scaler_state_dict\"] = scaler.state_dict()\n",
    "    checkpoint[\"losses\"] = losses\n",
    "    checkpoint[\"ppls\"] = ppls\n",
    "    \n",
    "    path = path.split(\".\")[0] + \"-checkpoint\"\n",
    "    \n",
    "    elements = [int(element.split(\"-\")[-1].split(\".\")[0]) for element in glob.glob(f\"{path}*\")]\n",
    "    max_idx = np.max(elements)\n",
    "    new_idx = max_idx + 1\n",
    "\n",
    "    new_path = f\"{path}-{new_idx:05d}.pth\"\n",
    "    print()\n",
    "    print(f\"Save file at: {new_path} ...\")\n",
    "    torch.save(checkpoint, f\"{path}-{new_idx:05d}.pth\")\n",
    "    time.sleep(1)\n",
    "    print(\"... finished!\")\n",
    "    print()\n",
    "def load_checkpoint(path=None):\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model = Model(vocab_size=VOCAB_SIZE, n_embd=N_EMB, block_size=LEN_CONTEXT, n_head=N_HEADS, n_layer=N_LAYERS, dropout=DROPOUT).to(DEVICE)\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=LR)\n",
    "        scaler = torch.cuda.amp.GradScaler(enabled=True)\n",
    "        \n",
    "        if path is not None:\n",
    "            checkpoint = torch.load(path)\n",
    "            \n",
    "            model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "            optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "            scaler.load_state_dict(checkpoint[\"scaler_state_dict\"])\n",
    "        \n",
    "            token_count = checkpoint[\"token_count\"]\n",
    "        \n",
    "            losses = checkpoint[\"losses\"]\n",
    "            ppls = checkpoint[\"ppls\"]\n",
    "        \n",
    "            n_epoch_ = checkpoint[\"epoch\"]\n",
    "            n_ = checkpoint[\"batch\"] + 1\n",
    "            bs_ = checkpoint[\"batch_acc\"]\n",
    "        else:\n",
    "            token_count = 0\n",
    "            losses = [[0, 0, 0, 0]]\n",
    "            ppls = [[0, 0, 0, 0]]\n",
    "            n_epoch_ = 0\n",
    "            n_ = 0\n",
    "            bs_ = 0\n",
    "\n",
    "        # print(\"Compile model...\")\n",
    "        # model = torch.compile(model)\n",
    "        # print(\"...done!\")\n",
    "        # print()\n",
    "    \n",
    "        return model, optimizer, scaler, token_count, losses, ppls, n_epoch_, n_, bs_  \n",
    "def train(loader, path, n_save=25):\n",
    "\n",
    "    model, optimizer, scaler, token_count, losses, ppls, n_epoch_, n_, bs_ = load_checkpoint(path)\n",
    "\n",
    "    print(f\"Number of parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad) / 1000000:.2f} Mio\")\n",
    "    print()\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    iterator = iter(loader)\n",
    "    N = int(np.floor(len(loader) / BATCH_SUM))\n",
    "    \n",
    "    for n_epoch in range(n_epoch_, N_EPOCHS):\n",
    "        for n in range(n_, N):\n",
    "            for bs in range(BATCH_SUM):\n",
    "                \n",
    "                batch = next(iterator)\n",
    "            \n",
    "                in_tokens = batch[\"tokens\"][:, :-1].to(DEVICE)\n",
    "                out_tokens = batch[\"tokens\"][:, 1:].to(DEVICE)\n",
    "                \n",
    "                logits, latent = model(in_tokens)\n",
    "                loss = F.cross_entropy(logits.view(out_tokens.shape[0] * out_tokens.shape[1], -1), out_tokens.view(-1))\n",
    "                scaler.scale(loss).backward()\n",
    "\n",
    "                losses.append((n_epoch, n, bs, loss.item()))\n",
    "                ppls.append((n_epoch, n, bs, torch.exp(loss).item()))\n",
    "                token_count += len(batch) * LEN_CONTEXT\n",
    "\n",
    "                losses_ = np.asarray(losses)[-10000:, -1]\n",
    "                ppls_ = np.asarray(ppls)[-10000:, -1]\n",
    "                print(f\"\\r{n_epoch + 1:03d}|{N_EPOCHS}, {n + 1:04d}|{N}, {bs + 1:03d}|{BATCH_SUM}, loss: {losses_.mean():.5f}, ppl: {ppls_.mean():010.5f}, {token_count / 1_000_000:.5f} Mio tokens.\", end=\"\")\n",
    "\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "            if (n + 1) % 25 == 0:\n",
    "                print()\n",
    "\n",
    "            if (n + 1) % n_save == 0:\n",
    "                save_checkpoint(n_epoch, n, bs, token_count, losses, ppls, model, optimizer, scaler, FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88dc5a6f-9c68-492e-952c-45f5fde68549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "#     model, optimizer, scaler, token_count, losses, ppls, n_epoch_, n_, bs_ = load_checkpoint(f\"models/text_embedding-checkpoint-00000.pth\")\n",
    "#     model.eval()\n",
    "#     batch = next(iter(loader))\n",
    "#     in_tokens = batch[\"tokens\"].to(DEVICE)\n",
    "#     logits, latent = model(in_tokens)\n",
    "#     print(logits.shape)\n",
    "#     print(latent.shape)\n",
    "#     logits.detach().cpu().numpy()\n",
    "#     latent.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c8dedf5-afdc-42ad-a3cf-b790dda62351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 290.22 Mio\n",
      "\n",
      "001|100, 0775|2918, 032|32, loss: 4.91671, ppl: 0138.06357, 12.69760 Mio tokens.\n",
      "001|100, 0800|2918, 032|32, loss: 4.88770, ppl: 0134.02805, 13.10720 Mio tokens.\n",
      "001|100, 0825|2918, 032|32, loss: 4.85912, ppl: 0130.18149, 13.51680 Mio tokens.\n",
      "001|100, 0850|2918, 032|32, loss: 4.83248, ppl: 0126.71584, 13.92640 Mio tokens.\n",
      "001|100, 0875|2918, 032|32, loss: 4.80753, ppl: 0123.54368, 14.33600 Mio tokens.\n",
      "001|100, 0900|2918, 032|32, loss: 4.78333, ppl: 0120.55527, 14.74560 Mio tokens.\n",
      "001|100, 0925|2918, 032|32, loss: 4.76140, ppl: 0117.90247, 15.15520 Mio tokens.\n",
      "001|100, 0950|2918, 032|32, loss: 4.73935, ppl: 0115.29356, 15.56480 Mio tokens.\n",
      "001|100, 0975|2918, 032|32, loss: 4.71858, ppl: 0112.90876, 15.97440 Mio tokens.\n",
      "001|100, 1000|2918, 032|32, loss: 4.69830, ppl: 0110.62538, 16.38400 Mio tokens.\n",
      "\n",
      "Save file at: models/text_embedding-checkpoint-00001.pth ...\n",
      "... finished!\n",
      "\n",
      "001|100, 1025|2918, 032|32, loss: 4.67830, ppl: 0108.41878, 16.79360 Mio tokens.\n",
      "001|100, 1050|2918, 032|32, loss: 4.65889, ppl: 0106.32405, 17.20320 Mio tokens.\n",
      "001|100, 1075|2918, 032|32, loss: 4.64053, ppl: 0104.37988, 17.61280 Mio tokens.\n",
      "001|100, 1100|2918, 032|32, loss: 4.62292, ppl: 0102.55318, 18.02240 Mio tokens.\n",
      "001|100, 1125|2918, 032|32, loss: 4.60584, ppl: 0100.79154, 18.43200 Mio tokens.\n",
      "001|100, 1150|2918, 032|32, loss: 4.59000, ppl: 0099.20171, 18.84160 Mio tokens.\n",
      "001|100, 1175|2918, 032|32, loss: 4.57419, ppl: 0097.63930, 19.25120 Mio tokens.\n",
      "001|100, 1200|2918, 032|32, loss: 4.55745, ppl: 0096.02491, 19.66080 Mio tokens.\n",
      "001|100, 1225|2918, 032|32, loss: 4.54104, ppl: 0094.46133, 20.07040 Mio tokens.\n",
      "001|100, 1250|2918, 032|32, loss: 4.52562, ppl: 0093.00721, 20.48000 Mio tokens.\n",
      "\n",
      "Save file at: models/text_embedding-checkpoint-00002.pth ...\n",
      "... finished!\n",
      "\n",
      "001|100, 1275|2918, 032|32, loss: 4.51025, ppl: 0091.58505, 20.88960 Mio tokens.\n",
      "001|100, 1300|2918, 032|32, loss: 4.49621, ppl: 0090.29987, 21.29920 Mio tokens.\n",
      "001|100, 1325|2918, 032|32, loss: 4.48288, ppl: 0089.10582, 21.70880 Mio tokens.\n",
      "001|100, 1350|2918, 032|32, loss: 4.47012, ppl: 0087.97409, 22.11840 Mio tokens.\n",
      "001|100, 1375|2918, 032|32, loss: 4.45724, ppl: 0086.84304, 22.52800 Mio tokens.\n",
      "001|100, 1400|2918, 032|32, loss: 4.44454, ppl: 0085.74701, 22.93760 Mio tokens.\n",
      "001|100, 1425|2918, 032|32, loss: 4.43236, ppl: 0084.70555, 23.34720 Mio tokens.\n",
      "001|100, 1450|2918, 032|32, loss: 4.41934, ppl: 0083.59658, 23.75680 Mio tokens.\n",
      "001|100, 1475|2918, 032|32, loss: 4.40682, ppl: 0082.55542, 24.16640 Mio tokens.\n",
      "001|100, 1500|2918, 032|32, loss: 4.39505, ppl: 0081.59035, 24.57600 Mio tokens.\n",
      "\n",
      "Save file at: models/text_embedding-checkpoint-00003.pth ...\n",
      "... finished!\n",
      "\n",
      "001|100, 1525|2918, 032|32, loss: 4.38490, ppl: 0080.76512, 24.98560 Mio tokens.\n",
      "001|100, 1550|2918, 032|32, loss: 4.37368, ppl: 0079.86115, 25.39520 Mio tokens.\n",
      "001|100, 1575|2918, 032|32, loss: 4.36295, ppl: 0079.00346, 25.80480 Mio tokens.\n",
      "001|100, 1600|2918, 032|32, loss: 4.35195, ppl: 0078.14049, 26.21440 Mio tokens.\n",
      "001|100, 1625|2918, 032|32, loss: 4.34139, ppl: 0077.31831, 26.62400 Mio tokens.\n",
      "001|100, 1650|2918, 032|32, loss: 4.33075, ppl: 0076.49522, 27.03360 Mio tokens.\n",
      "001|100, 1675|2918, 032|32, loss: 4.32048, ppl: 0075.71063, 27.44320 Mio tokens.\n",
      "001|100, 1700|2918, 032|32, loss: 4.31033, ppl: 0074.94112, 27.85280 Mio tokens.\n",
      "001|100, 1725|2918, 032|32, loss: 4.30040, ppl: 0074.19772, 28.26240 Mio tokens.\n",
      "001|100, 1750|2918, 032|32, loss: 4.29049, ppl: 0073.47050, 28.67200 Mio tokens.\n",
      "\n",
      "Save file at: models/text_embedding-checkpoint-00004.pth ...\n",
      "... finished!\n",
      "\n",
      "001|100, 1775|2918, 032|32, loss: 4.28075, ppl: 0072.76189, 29.08160 Mio tokens.\n",
      "001|100, 1800|2918, 032|32, loss: 4.27108, ppl: 0072.06226, 29.49120 Mio tokens.\n",
      "001|100, 1825|2918, 032|32, loss: 4.26223, ppl: 0071.42493, 29.90080 Mio tokens.\n",
      "001|100, 1850|2918, 032|32, loss: 4.25240, ppl: 0070.72658, 30.31040 Mio tokens.\n",
      "001|100, 1875|2918, 032|32, loss: 4.24317, ppl: 0070.08384, 30.72000 Mio tokens.\n",
      "001|100, 1900|2918, 032|32, loss: 4.23383, ppl: 0069.42878, 31.12960 Mio tokens.\n",
      "001|100, 1925|2918, 032|32, loss: 4.22511, ppl: 0068.83104, 31.53920 Mio tokens.\n",
      "001|100, 1950|2918, 032|32, loss: 4.21534, ppl: 0068.15877, 31.94880 Mio tokens.\n",
      "001|100, 1975|2918, 032|32, loss: 4.20619, ppl: 0067.52883, 32.35840 Mio tokens.\n",
      "001|100, 2000|2918, 032|32, loss: 4.19763, ppl: 0066.94874, 32.76800 Mio tokens.\n",
      "\n",
      "Save file at: models/text_embedding-checkpoint-00005.pth ...\n",
      "... finished!\n",
      "\n",
      "001|100, 2025|2918, 032|32, loss: 4.18944, ppl: 0066.40350, 33.17760 Mio tokens.\n",
      "001|100, 2050|2918, 032|32, loss: 4.18129, ppl: 0065.86050, 33.58720 Mio tokens.\n",
      "001|100, 2066|2918, 017|32, loss: 4.17545, ppl: 0065.48020, 33.84166 Mio tokens."
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodels/text_embedding-checkpoint-00000.pth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_save\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m250\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# train(loader, None, n_save=1)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[7], line 85\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(loader, path, n_save)\u001b[0m\n\u001b[1;32m     83\u001b[0m logits, latent \u001b[38;5;241m=\u001b[39m model(in_tokens)\n\u001b[1;32m     84\u001b[0m loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mcross_entropy(logits\u001b[38;5;241m.\u001b[39mview(out_tokens\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m out_tokens\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), out_tokens\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m---> 85\u001b[0m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     87\u001b[0m losses\u001b[38;5;241m.\u001b[39mappend((n_epoch, n, bs, loss\u001b[38;5;241m.\u001b[39mitem()))\n\u001b[1;32m     88\u001b[0m ppls\u001b[38;5;241m.\u001b[39mappend((n_epoch, n, bs, torch\u001b[38;5;241m.\u001b[39mexp(loss)\u001b[38;5;241m.\u001b[39mitem()))\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(loader, f\"models/text_embedding-checkpoint-00000.pth\", n_save=250)\n",
    "# train(loader, None, n_save=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c9dd09-d550-4ad7-bd2d-9fa9d6c0a374",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
