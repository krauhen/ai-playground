{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad879c98-a14d-4089-8b4e-d5041c532a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "import math\n",
    "import os\n",
    "import torch\n",
    "import pathlib\n",
    "import time\n",
    "import tiktoken\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.utils.data as torch_data\n",
    "import torchvision as tv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dea7c5e8-638b-47b9-aff1-835209c2ab25",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch_data.Dataset):\n",
    "    def __init__(self, tokenizer, len_context):\n",
    "\n",
    "        self.tokenizer = tiktoken.encoding_for_model(tokenizer)\n",
    "        self.len_context = len_context\n",
    "        self.elements = sorted(glob.glob(f\"/mnt/data/wikipedia/tokens/{tokenizer}/{len_context}/*\")) \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.elements)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        tokens_filename = self.elements[idx]\n",
    "        filename = tokens_filename.split(\"/\")[-1]\n",
    "        text_filename = os.path.join(f\"/mnt/data/wikipedia/text\", filename)\n",
    "        \n",
    "        with open(tokens_filename, \"rb\") as f:\n",
    "            tokens = json.load(f)[\"tokens\"]\n",
    "\n",
    "        with open(text_filename, \"rb\") as f:\n",
    "            text = json.load(f)[\"text\"]\n",
    "\n",
    "        tokens = tokens[:self.len_context + 1]\n",
    "        tokens = torch.from_numpy(np.array(tokens)).to(torch.long)\n",
    "        \n",
    "        element = dict()\n",
    "        element[\"text\"] = text\n",
    "        element[\"tokens\"] = tokens\n",
    "\n",
    "        return element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "142db1df-fb59-44ae-a256-2cc705624e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "SHUFFLE = True\n",
    "NUM_WORKERS = 16\n",
    "DEVICE = \"cuda\"\n",
    "LR = 1e-4\n",
    "N_EPOCHS = 100\n",
    "BATCH_SIZE = 32 + 8\n",
    "BATCH_SUM = 32\n",
    "\n",
    "TOKENIZER = \"gpt2\"\n",
    "LEN_CONTEXT = 256\n",
    "N_EMB = 2048\n",
    "N_HEADS = 12\n",
    "N_LAYERS = 7\n",
    "DROPOUT = 0.1\n",
    "\n",
    "FILE_PATH = \"models/text_embedding.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c061d751-30c2-49dc-a1fd-b0cccc0bf76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(TOKENIZER, LEN_CONTEXT)\n",
    "VOCAB_SIZE = dataset.tokenizer.n_vocab\n",
    "loader = torch_data.DataLoader(dataset, shuffle=SHUFFLE, pin_memory=True, num_workers=NUM_WORKERS, batch_size=BATCH_SIZE)\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e855991-974c-44f2-af55-a7d59c2c987a",
   "metadata": {},
   "outputs": [],
   "source": [
    "element = dataset[np.random.randint(0, len(dataset))]\n",
    "tokens = element[\"tokens\"]\n",
    "print(tokens.shape)\n",
    "batch = next(iter(loader))\n",
    "tokens = batch[\"tokens\"]\n",
    "print(tokens.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a94013-d437-4755-bbe7-2f3090bc8407",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    def __init__(self, head_size, n_embd, block_size, dropout):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B,T,C = x.shape\n",
    "        k = self.key(x)\n",
    "        q = self.query(x)\n",
    "        wei = q @ k.transpose(-2,-1) * k.shape[-1]**-0.5\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf'))\n",
    "        wei = F.softmax(wei, dim=-1)\n",
    "        wei = self.dropout(wei)\n",
    "        v = self.value(x)\n",
    "        out = wei @ v\n",
    "        return out\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, num_heads, head_size, n_embd, block_size, dropout):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size, n_embd, block_size, dropout) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(head_size * num_heads, n_embd)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out\n",
    "class FeedFoward(nn.Module):\n",
    "    def __init__(self, n_embd, dropout):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4 * n_embd),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embd, n_embd),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, n_head, n_embd, block_size, dropout):\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head\n",
    "        self.sa = MultiHeadAttention(n_head, head_size, n_embd, block_size, dropout)\n",
    "        self.ffwd = FeedFoward(n_embd, dropout)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.sa(self.ln1(x))\n",
    "        x = x + self.ffwd(self.ln2(x))\n",
    "        return x\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, vocab_size, n_embd, block_size, n_head, n_layer, dropout):\n",
    "        super().__init__()\n",
    "        self.block_size = block_size\n",
    "        self.token_embedding = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding = nn.Embedding(block_size, n_embd)\n",
    "\n",
    "        shape = 0\n",
    "        blocks = []\n",
    "        for i in range(n_layer):\n",
    "            blocks.append(Block(n_head, n_embd // 2**i, block_size, dropout))\n",
    "            blocks.append(nn.AvgPool1d(kernel_size=2, stride=2))\n",
    "            shape = n_embd // 2**(i + 1)\n",
    "        self.down_blocks = nn.Sequential(*blocks)\n",
    "        \n",
    "        blocks = []\n",
    "        for i in range(n_layer):\n",
    "            blocks.append(Block(n_head, shape, block_size, dropout))\n",
    "            blocks.append(nn.Upsample(scale_factor=2, mode='nearest'))\n",
    "            shape = shape * 2\n",
    "        self.up_blocks = nn.Sequential(*blocks)\n",
    "        \n",
    "        self.ln_f = nn.LayerNorm(n_embd)\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    def forward(self, idx):\n",
    "        tok_emb = self.token_embedding(idx)\n",
    "        pos_emb = self.position_embedding(torch.arange(idx.shape[1], device=idx.device))\n",
    "        x = tok_emb + pos_emb \n",
    "        latent = self.down_blocks(x)\n",
    "        x = self.up_blocks(latent)\n",
    "        x = self.ln_f(x)\n",
    "        logits = self.lm_head(x)\n",
    "        return logits, latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9780dfb-e78c-4b29-87be-44a11ca23253",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(epoch, batch, batch_acc, token_count, losses, ppls, model, optimizer, scaler, path):\n",
    "    checkpoint = dict()\n",
    "    checkpoint[\"epoch\"] = epoch\n",
    "    checkpoint[\"batch\"] = batch\n",
    "    checkpoint[\"batch_acc\"] = batch_acc\n",
    "    checkpoint[\"token_count\"] = token_count\n",
    "    checkpoint[\"model_state_dict\"] = model.state_dict()\n",
    "    checkpoint[\"optimizer_state_dict\"] = optimizer.state_dict()\n",
    "    checkpoint[\"scaler_state_dict\"] = scaler.state_dict()\n",
    "    checkpoint[\"losses\"] = losses\n",
    "    checkpoint[\"ppls\"] = ppls\n",
    "    \n",
    "    path = path.split(\".\")[0] + \"-checkpoint\"\n",
    "    \n",
    "    elements = [int(element.split(\"-\")[-1].split(\".\")[0]) for element in glob.glob(f\"{path}*\")]\n",
    "    max_idx = np.max(elements)\n",
    "    new_idx = max_idx + 1\n",
    "\n",
    "    new_path = f\"{path}-{new_idx:05d}.pth\"\n",
    "    print()\n",
    "    print(f\"Save file at: {new_path} ...\")\n",
    "    torch.save(checkpoint, f\"{path}-{new_idx:05d}.pth\")\n",
    "    time.sleep(1)\n",
    "    print(\"... finished!\")\n",
    "    print()\n",
    "def load_checkpoint(path=None):\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model = Model(vocab_size=VOCAB_SIZE, n_embd=N_EMB, block_size=LEN_CONTEXT, n_head=N_HEADS, n_layer=N_LAYERS, dropout=DROPOUT).to(DEVICE)\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=LR)\n",
    "        scaler = torch.cuda.amp.GradScaler(enabled=True)\n",
    "        \n",
    "        if path is not None:\n",
    "            checkpoint = torch.load(path)\n",
    "            \n",
    "            model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "            optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "            scaler.load_state_dict(checkpoint[\"scaler_state_dict\"])\n",
    "        \n",
    "            token_count = checkpoint[\"token_count\"]\n",
    "        \n",
    "            losses = checkpoint[\"losses\"]\n",
    "            ppls = checkpoint[\"ppls\"]\n",
    "        \n",
    "            n_epoch_ = checkpoint[\"epoch\"]\n",
    "            n_ = checkpoint[\"batch\"] + 1\n",
    "            bs_ = checkpoint[\"batch_acc\"]\n",
    "        else:\n",
    "            token_count = 0\n",
    "            losses = [[0, 0, 0, 0]]\n",
    "            ppls = [[0, 0, 0, 0]]\n",
    "            n_epoch_ = 0\n",
    "            n_ = 0\n",
    "            bs_ = 0\n",
    "\n",
    "        # print(\"Compile model...\")\n",
    "        # model = torch.compile(model)\n",
    "        # print(\"...done!\")\n",
    "        # print()\n",
    "    \n",
    "        return model, optimizer, scaler, token_count, losses, ppls, n_epoch_, n_, bs_  \n",
    "def train(loader, path, n_save=25):\n",
    "\n",
    "    model, optimizer, scaler, token_count, losses, ppls, n_epoch_, n_, bs_ = load_checkpoint(path)\n",
    "\n",
    "    print(f\"Number of parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad) / 1000000:.2f} Mio\")\n",
    "    print()\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    iterator = iter(loader)\n",
    "    N = int(np.floor(len(loader) / BATCH_SUM))\n",
    "    \n",
    "    for n_epoch in range(n_epoch_, N_EPOCHS):\n",
    "        for n in range(n_, N):\n",
    "            for bs in range(BATCH_SUM):\n",
    "                \n",
    "                batch = next(iterator)\n",
    "            \n",
    "                in_tokens = batch[\"tokens\"][:, :-1].to(DEVICE)\n",
    "                out_tokens = batch[\"tokens\"][:, 1:].to(DEVICE)\n",
    "                \n",
    "                logits, latent = model(in_tokens)\n",
    "                loss = F.cross_entropy(logits.view(out_tokens.shape[0] * out_tokens.shape[1], -1), out_tokens.view(-1))\n",
    "                scaler.scale(loss).backward()\n",
    "\n",
    "                losses.append((n_epoch, n, bs, loss.item()))\n",
    "                ppls.append((n_epoch, n, bs, torch.exp(loss).item()))\n",
    "                token_count += len(batch) * LEN_CONTEXT\n",
    "\n",
    "                losses_ = np.asarray(losses)[-10000:, -1]\n",
    "                ppls_ = np.asarray(ppls)[-10000:, -1]\n",
    "                print(f\"\\r{n_epoch + 1:03d}|{N_EPOCHS}, {n + 1:04d}|{N}, {bs + 1:03d}|{BATCH_SUM}, loss: {losses_.mean():.5f}, ppl: {ppls_.mean():010.5f}, {token_count / 1_000_000:.5f} Mio tokens.\", end=\"\")\n",
    "\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "            if (n + 1) % 25 == 0:\n",
    "                print()\n",
    "\n",
    "            if (n + 1) % n_save == 0:\n",
    "                save_checkpoint(n_epoch, n, bs, token_count, losses, ppls, model, optimizer, scaler, FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88dc5a6f-9c68-492e-952c-45f5fde68549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "#     model, optimizer, scaler, token_count, losses, ppls, n_epoch_, n_, bs_ = load_checkpoint(f\"models/text_embedding-checkpoint-00000.pth\")\n",
    "#     model.eval()\n",
    "#     batch = next(iter(loader))\n",
    "#     in_tokens = batch[\"tokens\"].to(DEVICE)\n",
    "#     logits, latent = model(in_tokens)\n",
    "#     print(logits.shape)\n",
    "#     print(latent.shape)\n",
    "#     logits.detach().cpu().numpy()\n",
    "#     latent.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8dedf5-afdc-42ad-a3cf-b790dda62351",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(loader, f\"models/text_embedding-checkpoint-00000.pth\", n_save=250)\n",
    "# train(loader, None, n_save=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c9dd09-d550-4ad7-bd2d-9fa9d6c0a374",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
