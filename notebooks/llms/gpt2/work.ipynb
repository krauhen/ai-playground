{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad879c98-a14d-4089-8b4e-d5041c532a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/henning/.local/lib/python3.11/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import glob\n",
    "import math\n",
    "import os\n",
    "import torch\n",
    "import pathlib\n",
    "import time\n",
    "import tiktoken\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.utils.data as torch_data\n",
    "import torchvision as tv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1849807-1ab5-41a8-aeb8-f9aeff83f030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.set_float32_matmul_precision('high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2456690-17d0-43b2-8e6e-62feabeaafb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch_data.Dataset):\n",
    "    def __init__(self, tokenizer, len_context):\n",
    "\n",
    "        self.tokenizer = tiktoken.encoding_for_model(tokenizer)\n",
    "        self.len_context = len_context\n",
    "        self.elements = sorted(glob.glob(f\"/mnt/data/wikipedia/tokens/{tokenizer}/{len_context}/*\")) \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.elements)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        tokens_filename = self.elements[idx]\n",
    "        filename = tokens_filename.split(\"/\")[-1]\n",
    "        text_filename = os.path.join(f\"/mnt/data/wikipedia/text\", filename)\n",
    "        \n",
    "        with open(tokens_filename, \"rb\") as f:\n",
    "            tokens = json.load(f)[\"tokens\"]\n",
    "\n",
    "        with open(text_filename, \"rb\") as f:\n",
    "            text = json.load(f)[\"text\"]\n",
    "\n",
    "        tokens = tokens[:self.len_context + 1]\n",
    "        tokens = torch.from_numpy(np.array(tokens)).to(torch.long)\n",
    "        \n",
    "        element = dict()\n",
    "        element[\"text\"] = text\n",
    "        element[\"tokens\"] = tokens\n",
    "\n",
    "        del text\n",
    "        del tokens\n",
    "\n",
    "        return element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "142db1df-fb59-44ae-a256-2cc705624e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "SHUFFLE = True\n",
    "NUM_WORKERS = 16\n",
    "DEVICE = \"cuda\"\n",
    "LR = 1e-4\n",
    "N_EPOCHS = 100\n",
    "BATCH_SIZE = 6\n",
    "BATCH_SUM = 170\n",
    "\n",
    "TOKENIZER = \"gpt2\"\n",
    "LEN_CONTEXT = 256\n",
    "N_EMB = 1280\n",
    "N_HEADS = 20\n",
    "N_LAYERS = 36\n",
    "DROPOUT = 0.1\n",
    "\n",
    "FILE_PATH = \"models/gpt2-large.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c061d751-30c2-49dc-a1fd-b0cccc0bf76a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3735788\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset(TOKENIZER, LEN_CONTEXT)\n",
    "VOCAB_SIZE = dataset.tokenizer.n_vocab\n",
    "loader = torch_data.DataLoader(dataset, shuffle=SHUFFLE, pin_memory=True, num_workers=NUM_WORKERS, batch_size=BATCH_SIZE)\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e855991-974c-44f2-af55-a7d59c2c987a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([257])\n",
      "torch.Size([6, 257])\n"
     ]
    }
   ],
   "source": [
    "element = dataset[np.random.randint(0, len(dataset))]\n",
    "tokens = element[\"tokens\"]\n",
    "print(tokens.shape)\n",
    "batch = next(iter(loader))\n",
    "tokens = batch[\"tokens\"]\n",
    "print(tokens.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7a94013-d437-4755-bbe7-2f3090bc8407",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    def __init__(self, head_size, n_embd, block_size, dropout):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B,T,C = x.shape\n",
    "        k = self.key(x)\n",
    "        q = self.query(x)\n",
    "        wei = q @ k.transpose(-2,-1) * k.shape[-1]**-0.5\n",
    "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf'))\n",
    "        wei = F.softmax(wei, dim=-1)\n",
    "        wei = self.dropout(wei)\n",
    "        v = self.value(x)\n",
    "        out = wei @ v\n",
    "        return out\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, num_heads, head_size, n_embd, block_size, dropout):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([Head(head_size, n_embd, block_size, dropout) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(head_size * num_heads, n_embd)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
    "        out = self.dropout(self.proj(out))\n",
    "        return out\n",
    "class FeedFoward(nn.Module):\n",
    "    def __init__(self, n_embd, dropout):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(n_embd, 4 * n_embd),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * n_embd, n_embd),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "class Block(nn.Module):\n",
    "    def __init__(self, n_head, n_embd, block_size, dropout):\n",
    "        super().__init__()\n",
    "        head_size = n_embd // n_head\n",
    "        self.sa = MultiHeadAttention(n_head, head_size, n_embd, block_size, dropout)\n",
    "        self.ffwd = FeedFoward(n_embd, dropout)\n",
    "        self.ln1 = nn.LayerNorm(n_embd)\n",
    "        self.ln2 = nn.LayerNorm(n_embd)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.sa(self.ln1(x))\n",
    "        x = x + self.ffwd(self.ln2(x))\n",
    "        return x\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, vocab_size, n_embd, block_size, n_head, n_layer, dropout):\n",
    "        super().__init__()\n",
    "        self.block_size = block_size\n",
    "        self.token_embedding = nn.Embedding(vocab_size, n_embd)\n",
    "        self.position_embedding = nn.Embedding(block_size, n_embd)\n",
    "        self.blocks = nn.Sequential(*[Block(n_head, n_embd, block_size, dropout) for _ in range(n_layer)])\n",
    "        self.ln_f = nn.LayerNorm(n_embd)\n",
    "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None:\n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        elif isinstance(module, nn.Embedding):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "\n",
    "    def forward(self, idx):\n",
    "        tok_emb = self.token_embedding(idx)\n",
    "        pos_emb = self.position_embedding(torch.arange(idx.shape[1], device=idx.device))\n",
    "        x = tok_emb + pos_emb \n",
    "        x = self.blocks(x)\n",
    "        x = self.ln_f(x)\n",
    "        logits = self.lm_head(x)\n",
    "        return logits\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            idx_cond = idx[:, -self.block_size:]\n",
    "            logits = self(idx_cond)\n",
    "            logits = logits[:, -1, :]\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            idx = torch.cat((idx, idx_next), dim=1)\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9780dfb-e78c-4b29-87be-44a11ca23253",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(epoch, batch, batch_acc, token_count, losses, ppls, model, optimizer, scaler, path):\n",
    "    checkpoint = dict()\n",
    "    checkpoint[\"epoch\"] = epoch\n",
    "    checkpoint[\"batch\"] = batch\n",
    "    checkpoint[\"batch_acc\"] = batch_acc\n",
    "    checkpoint[\"token_count\"] = token_count\n",
    "    checkpoint[\"model_state_dict\"] = model.state_dict()\n",
    "    checkpoint[\"optimizer_state_dict\"] = optimizer.state_dict()\n",
    "    checkpoint[\"scaler_state_dict\"] = scaler.state_dict()\n",
    "    checkpoint[\"losses\"] = losses\n",
    "    checkpoint[\"ppls\"] = ppls\n",
    "    \n",
    "    path = path.split(\".\")[0] + \"-checkpoint\"\n",
    "    \n",
    "    elements = [int(element.split(\"-\")[-1].split(\".\")[0]) for element in glob.glob(f\"{path}*\")]\n",
    "    max_idx = np.max(elements)\n",
    "    new_idx = max_idx + 1\n",
    "\n",
    "    new_path = f\"{path}-{new_idx:05d}.pth\"\n",
    "    print()\n",
    "    print(f\"Save file at: {new_path} ...\")\n",
    "    torch.save(checkpoint, f\"{path}-{new_idx:05d}.pth\")\n",
    "    time.sleep(1)\n",
    "    print(\"... finished!\")\n",
    "    print()\n",
    "def load_checkpoint(path=None):\n",
    "\n",
    "    with torch.no_grad():\n",
    "        model = Model(vocab_size=VOCAB_SIZE, n_embd=N_EMB, block_size=LEN_CONTEXT, n_head=N_HEADS, n_layer=N_LAYERS, dropout=DROPOUT).to(DEVICE)\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=LR)\n",
    "        scaler = torch.cuda.amp.GradScaler(enabled=True)\n",
    "        \n",
    "        if path is not None:\n",
    "            checkpoint = torch.load(path)\n",
    "            \n",
    "            model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "            optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "            scaler.load_state_dict(checkpoint[\"scaler_state_dict\"])\n",
    "        \n",
    "            token_count = checkpoint[\"token_count\"]\n",
    "        \n",
    "            losses = checkpoint[\"losses\"]\n",
    "            ppls = checkpoint[\"ppls\"]\n",
    "        \n",
    "            n_epoch_ = checkpoint[\"epoch\"]\n",
    "            n_ = checkpoint[\"batch\"] + 1\n",
    "            bs_ = checkpoint[\"batch_acc\"]\n",
    "        else:\n",
    "            token_count = 0\n",
    "            losses = [[0, 0, 0, 0]]\n",
    "            ppls = [[0, 0, 0, 0]]\n",
    "            n_epoch_ = 0\n",
    "            n_ = 0\n",
    "            bs_ = 0\n",
    "\n",
    "        # print(\"Compile model...\")\n",
    "        # model = torch.compile(model)\n",
    "        # print(\"...done!\")\n",
    "        # print()\n",
    "    \n",
    "        return model, optimizer, scaler, token_count, losses, ppls, n_epoch_, n_, bs_  \n",
    "def generate_example():\n",
    "    with torch.no_grad():\n",
    "        batch = next(iter(loader))\n",
    "        tokens = batch[\"tokens\"]\n",
    "        in_tokens = tokens[:, :-1].to(DEVICE)\n",
    "        out_tokens = model.generate(in_tokens, 16)\n",
    "    \n",
    "        in_tokens = in_tokens.detach().cpu().numpy()\n",
    "        out_tokens = out_tokens.detach().cpu().numpy()\n",
    "    \n",
    "        for in_tokens_, out_tokens_ in zip(in_tokens, out_tokens):\n",
    "            in_text = dataset.tokenizer.decode(in_tokens_)\n",
    "            out_text = dataset.tokenizer.decode(out_tokens_)\n",
    "    \n",
    "            print(\"=======\")\n",
    "            print(\"IN\")\n",
    "            print(in_text)\n",
    "            print(\"OUT\")\n",
    "            print(out_text)\n",
    "            print(\"=======\")\n",
    "            print()\n",
    "def train(loader, path, n_save=25):\n",
    "\n",
    "    model, optimizer, scaler, token_count, losses, ppls, n_epoch_, n_, bs_ = load_checkpoint(path)\n",
    "\n",
    "    print(f\"Number of parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad) / 1000000:.2f} Mio\")\n",
    "    print()\n",
    "    \n",
    "    model.train()\n",
    "\n",
    "    iterator = iter(loader)\n",
    "    N = int(np.floor(len(loader) / BATCH_SUM))\n",
    "    \n",
    "    for n_epoch in range(n_epoch_, N_EPOCHS):\n",
    "        for n in range(n_, N):\n",
    "            for bs in range(BATCH_SUM):\n",
    "                \n",
    "                batch = next(iterator)\n",
    "            \n",
    "                in_tokens = batch[\"tokens\"][:, :-1].to(DEVICE)\n",
    "                out_tokens = batch[\"tokens\"][:, 1:].to(DEVICE)\n",
    "                \n",
    "                logits = model(in_tokens)\n",
    "                loss = F.cross_entropy(logits.view(out_tokens.shape[0] * out_tokens.shape[1], -1), out_tokens.view(-1))\n",
    "                scaler.scale(loss).backward()\n",
    "\n",
    "                losses.append((n_epoch, n, bs, loss.item()))\n",
    "                ppls.append((n_epoch, n, bs, torch.exp(loss).item()))\n",
    "                token_count += len(batch) * LEN_CONTEXT\n",
    "\n",
    "                losses_ = np.asarray(losses)[:, -1]\n",
    "                ppls_ = np.asarray(ppls)[:, -1]\n",
    "                print(f\"\\r{n_epoch + 1:03d}|{N_EPOCHS}, {n + 1:04d}|{N}, {bs + 1:03d}|{BATCH_SUM}, loss: {losses_.mean():.5f}, ppl: {ppls_.mean():010.5f}, {token_count / 1_000_000:.5f} Mio tokens.\", end=\"\")\n",
    "\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "            if (n + 1) % 25 == 0:\n",
    "                print()\n",
    "\n",
    "            if (n + 1) % n_save == 0:\n",
    "                save_checkpoint(n_epoch, n, bs, token_count, losses, ppls, model, optimizer, scaler, FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c8dedf5-afdc-42ad-a3cf-b790dda62351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 837.29 Mio\n",
      "\n",
      "001|100, 0725|3662, 170|170, loss: 5.29014, ppl: 0245.53678, 63.10400 Mio tokens.\n",
      "001|100, 0750|3662, 170|170, loss: 5.26613, ppl: 0240.92128, 65.28000 Mio tokens.\n",
      "\n",
      "Save file at: models/gpt2-large-checkpoint-00012.pth ...\n",
      "... finished!\n",
      "\n",
      "001|100, 0775|3662, 170|170, loss: 5.24284, ppl: 0236.51183, 67.45600 Mio tokens.\n",
      "001|100, 0800|3662, 170|170, loss: 5.21989, ppl: 0232.26715, 69.63200 Mio tokens.\n",
      "001|100, 0825|3662, 170|170, loss: 5.19745, ppl: 0228.19250, 71.80800 Mio tokens.\n",
      "001|100, 0850|3662, 170|170, loss: 5.17576, ppl: 0224.30272, 73.98400 Mio tokens.\n",
      "001|100, 0875|3662, 170|170, loss: 5.15462, ppl: 0220.56420, 76.16000 Mio tokens.\n",
      "001|100, 0900|3662, 170|170, loss: 5.13382, ppl: 0216.95849, 78.33600 Mio tokens.\n",
      "001|100, 0925|3662, 170|170, loss: 5.11328, ppl: 0213.47030, 80.51200 Mio tokens.\n",
      "001|100, 0950|3662, 170|170, loss: 5.09327, ppl: 0210.11495, 82.68800 Mio tokens.\n",
      "001|100, 0975|3662, 170|170, loss: 5.07341, ppl: 0206.86128, 84.86400 Mio tokens.\n",
      "001|100, 1000|3662, 170|170, loss: 5.05409, ppl: 0203.73110, 87.04000 Mio tokens.\n",
      "\n",
      "Save file at: models/gpt2-large-checkpoint-00013.pth ...\n",
      "... finished!\n",
      "\n",
      "001|100, 1025|3662, 170|170, loss: 5.03513, ppl: 0200.70788, 89.21600 Mio tokens.\n",
      "001|100, 1050|3662, 170|170, loss: 5.01650, ppl: 0197.78335, 91.39200 Mio tokens.\n",
      "001|100, 1075|3662, 170|170, loss: 4.99808, ppl: 0194.94491, 93.56800 Mio tokens.\n",
      "001|100, 1100|3662, 170|170, loss: 4.97980, ppl: 0192.18242, 95.74400 Mio tokens.\n",
      "001|100, 1125|3662, 170|170, loss: 4.96187, ppl: 0189.51013, 97.92000 Mio tokens.\n",
      "001|100, 1150|3662, 170|170, loss: 4.94409, ppl: 0186.90964, 100.09600 Mio tokens.\n",
      "001|100, 1175|3662, 170|170, loss: 4.92668, ppl: 0184.39263, 102.27200 Mio tokens.\n",
      "001|100, 1200|3662, 170|170, loss: 4.90926, ppl: 0181.93434, 104.44800 Mio tokens.\n",
      "001|100, 1219|3662, 026|170, loss: 4.89678, ppl: 0180.19256, 106.02803 Mio tokens."
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodels/gpt2-large-checkpoint-00000.pth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_save\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m250\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 106\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(loader, path, n_save)\u001b[0m\n\u001b[1;32m    104\u001b[0m logits \u001b[38;5;241m=\u001b[39m model(in_tokens)\n\u001b[1;32m    105\u001b[0m loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mcross_entropy(logits\u001b[38;5;241m.\u001b[39mview(out_tokens\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m out_tokens\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), out_tokens\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m--> 106\u001b[0m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    108\u001b[0m losses\u001b[38;5;241m.\u001b[39mappend((n_epoch, n, bs, loss\u001b[38;5;241m.\u001b[39mitem()))\n\u001b[1;32m    109\u001b[0m ppls\u001b[38;5;241m.\u001b[39mappend((n_epoch, n, bs, torch\u001b[38;5;241m.\u001b[39mexp(loss)\u001b[38;5;241m.\u001b[39mitem()))\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(loader, f\"models/gpt2-large-checkpoint-00000.pth\", n_save=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b4d884-cc43-4d4d-93c1-a10173b30210",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
